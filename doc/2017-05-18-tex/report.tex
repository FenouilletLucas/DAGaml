\documentclass[a4paper,10pt]{article}
%\usepackage{fullpage}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{mathabx}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{cite}

\lstset{breaklines=true,
  mathescape=true,
	%language=caml,
	numbers=left,
  numberstyle=\tiny \bf, %\color{blue},
  %stepnumber=2,
  numbersep=10pt,
  %firstnumber=11,
  numberfirstline=true
	}

\title{A Generalized Reduction of Ordered Binary Decision Diagram}
\author{Joan Thibault}

\newcommand{\includeframe}[4]{\makebox[#2\linewidth]{\includegraphics[page=#1,width=#2\linewidth,trim=0cm 0cm 0cm 0cm,clip=true,#3]{#4}}}

\begin{document}

\maketitle
\begin{abstract}
Reduced Ordered Binary Decision Diagram ((RO)BDD)\cite{Bryant1986, Somenzi1999} are the state-of-the-art representation for Boolean functions.
They are used in various fields such as logic synthesis, artificial intelligence or combinatorics.
However, BDDs suffer from to main issues: (1) their representation is memory expansive and (2) their manipulation is memory intensive as it induces many random memory accesses.


Various variations of ROBDD exist such as Zero-suppressed Decision Diagram (ZDD)\cite{IntroZDD}, Multi-valued Decision Diagram (MDD)\cite{IntroMDD, IntroMddRolf} and variations of the reduction rules such as "output inverter"\cite{BryantVariantN}, "input negation"\cite{MinatoVariants}, "shifting variables"\cite{MinatoVariants}, "dual edges"\cite{RolfVariantDual} or "copy node"\cite{RolfVariantCopy}.


In this report, we introduce a new generalization of the standard reduction rules that we call the "extraction of useless variables" or "extract U" for short.
Basically, it detects useless variables (i.e. variables which have no influence on the result of a given function) and extracts them from the local variable order.
This generalization allows to add/remove useless variables in linear time (in the number of variables), reduces the number of nodes and tends to reduce the overall memory cost.
However, several drawbacks arise: no in-place sifting (permutation of adjacent variables), bigger nodes of variable size and it slightly complexifies manipulations.


We implemented both the "extract U" and the "output negation" variants in an OCaml program and tested it against several benchmarks\cite{BenchSatlib, BenchLgsynth91, BenchIscas99}.
We observe an average of 25\% less nodes and 32\% less memory when representing circuits, and 3\% less nodes and memory when representing solutions from generated CNF formulas.
\end{abstract}


\newpage
\tableofcontents
\newpage
\newcommand{\shannon}[3]{#1 \longrightarrow_S #2, #3}
\newcommand{\N}{\mathbb{N}}%{\{0, 1\}}
\newcommand{\B}{\mathbb{B}}%{\{0, 1\}}
\newcommand{\F}{\mathbb{F}}%{\{0, 1\}}
\newcommand{\Y}{\mathbb{Y}}%{\{0, 1\}}
\newcommand{\I}{\mathbb{I}}%{\{0, 1\}}
\newcommand{\Ynode}{\Y\mathtt{-node}}

\section{Introduction}

Nowadays, it exists many critical systems which rely on digital circuits: in transportation (e.g. cars, train, plains) , communication (e.g. satellites), computation (e.g. data centers, super-computers), exploration (e.g. space rocket, rovers).
One way of minimizing risks in digital parts of these systems is to provide a formal proof that they respect their specification.
On the other hand, we want to minimize costs and energy consumption while maximizing performances of these digital circuits.
In order to efficiently optimize digital circuits we rely on complex programs.
However, these programs are rarely proven themselves, thus, circuits optimized using them might not be equivalent to the initial design, therefore, might not respect the specification.
The obvious solution would be to prove optimizing programs, however two majors issues arise : these programs are complex  (thus, proving them would be expansive) and might be proprietary (thus, one cannot check that the proof is correct).
A simpler alternative is to design a program which check that two digital circuits are equivalent.
With this alternative, the only piece of software which needs to be proven is the "equivalence checker".


In order to prove that two digital circuits are equivalent, their is two main algorithmic solutions:
Firstly, the DPLL (Davis–Putnam–Logemann–Loveland) algorithm.
This backtracking procedure is usually implemented with various heuristics such as \textit{unit propagation}, early conflict detection or \textit{conflict driven clause learning}.
Secondly, the compilation of both circuits into Reduced Ordered Binary Decision Diagrams (ROBDDs).
A ROBDD is a canonical structure which represent a function, thus, once compiled, the identity test can be performed in constant time.
However, the compilation might take an exponential time in the number of variable.
In this report we will focus on ROBDDs.


ROBDD have various other applications such as: Bounded Model Checking, Planning, Software Verification, Automatic Test Pattern Generation, Combinational Equivalence Checking or Combinatorial Interaction Testing.

%\begin{figure}
%\[f_n(x_0, x_1, \dots, x_{2n}, x_{2n+1}) = (x_0 \land x_1) \lor \dots \lor (x_{2n} \land x_{2n+1})\]
%\[g_n(x_0, x_1, \dots, x_{2n}, x_{2n+1}) = f_n(x_0, x_{n+1}, \dots, x_n, x_{2n+1})\]
%\caption{The ROBDD representing the function $f_n$ has a linear size in $n$, the one representing $g_n$ has a an exponential size in $n$.}
%\label{OrderExplosion}
%\end{figure}


However, BDDs are memory expansive as their size tends to grow exponentially with the number of variables.
Various variants have been invented in order to capture some semantic properties of the function and reduce the memory consumption.
For example, Zero suppressed binary Decision Diagram (ZDD) are better suited for representing sparse functions.
In this report we will use the "output inverter" variant\cite{BryantVariantN}, which extends the reduction rules in order to guarantee canonicity under negation.
Thus, in addition to reduce the size of the structure, allows to negate a function in constant time (reducing the set of useful binary operators to XOR and AND).
Other extensions of the reduction rules exist such as: "input negation"\cite{MinatoVariants} (each edge can complement the first locally first input), "shifting variables"\cite{MinatoVariants} (each edge store the number of useless variables before the next significant variables) or "dual edge"\cite{RolfVariantDual} (we define the dual of a function $f$ by $\bar{f} = X \longrightarrow \bar{f}(\bar{X})$, therefore the reduction works similarly to the "output inversion").


In addition to use the "output inverter" variant, we introduce a new variant which allows to extract useless variables (a.k.a non-support variables).
A useless variables, is a variable which does not change the results such as $x_1$ in $f(x_0, x_1, x_2) = x_0 \land x_2$ or $x_0$ in $g(x_0) = x_0 \land \lnot x_0$.
We call this new variant "extraction useless variables" or "U-extract" for short.


This report will be organized as follows. In Section~1, we formally introduce Boolean functions and useless variable. In Section~2, we introduce ROBDDs. In Section~3, we introduce the "U-extract" variant and prove that it maintains the canonicity. In Section~4, we expose an estimations of improvements on three different benchmarks \cite{BenchSatlib, BenchLgsynth91, BenchIscas99} using our implementation in OCaml.

\section{Notations}

Reduced Ordered Binary Decision Diagrams represent Boolean functions.
In this section we introduce notations necessary to their manipulation.


We denote the set of Booleans $\B = \{0, 1\}$.
The set of Boolean vector of size $n\in\N$ is denoted $\B^n$.
The set of Boolean functions of arity $n\in\N$ is denoted $\F_n = \B^n \longrightarrow \B$.


We denote conjunction by $\land$, disjunction by $\lor$, negation by $\lnot$.
We denote the Shannon operator by $\shannon{}{}{}$ defined by $\forall x, y, z\in\B, \shannon{x}{y}{z} = (\lnot x \land y) \lor (x \land z)$).

\paragraph{Restriction\\}

Let $f\in\F_{n+1}$ be a Boolean function of arity $n+1$, $i~(0\leq i < n+1)$ be an integer and $b\in\B$ be a Boolean.
We denote $f[i\leftarrow b]$ the Boolean function of arity $n$ defined by $f[i\leftarrow b](x_1, \dots, x_n) = f(x_0, \dots, x_{i-1}, b, x_i, \dots, x_n)$.
$f[i\leftarrow 0]$ (respectively $f[i\leftarrow 1]$) is called the $i$-th negative (respectively positive) restriction.

For each Boolean function $f$ of arity $n+1$, we denote $f[i\leftarrow b] = (x_1, ..., x_n) \rightarrow f(x_1, .., x_{i-1}, b, x_i, ..., x_n)$ the function of arity n called the i-th positive restriction of $f$ if $b=1$, the negative one otherwise.


Let $f$ be a function of arity $n+1$, we denote $f_0 = f[0\leftarrow 0]$ (respectively $f_1 = f[0\leftarrow 1]$) the function of arity $n$.

\paragraph{Construction\\}

Let $f, g \in F_n$ be Boolean functions of arity $n$ and $i~(0\leq i < n+1)$ be an integer.
We denote $f\star_ig$ the Boolean function of arity $n+1$ defined by $(f\star_ig)(x_0, \dots, x_{i-1}, y, x_i, \dots, x_n) = \shannon{y}{f(x_0, \dots, x_n)}{g(x_0, \dots, x_n)}$.

We denote $\star = \star_0$

Nb: $(f\star_i g)[i\leftarrow 0] = f$ and $ (f\star_i g)[i\leftarrow 1] = g$ ($(f\star g)_0 = f$ and $ (f\star g)_1 = g)$.

\paragraph{Expansion Theorem\\}
Let $f$ be a function of arity $n$, then $\forall i, 0\leq i < n \Rightarrow f = f[i\leftarrow 0]\star_i f[i\leftarrow 1]$ (in particular $f = f_0 \star f_1$)

\paragraph{Restriction Distributivity\\}

\begin{itemize}
\item $(\lnot f)[i\leftarrow b] = \lnot f[i\leftarrow b]$
\item $(f\land g)[i\leftarrow b] = f[i\leftarrow b] \land g[i\leftarrow b]$
\item $(f\lor g)[i\leftarrow b] = f[i\leftarrow b] \lor g[i\leftarrow b]$
\end{itemize}

\paragraph{Useless Variables\\}

We define, the support set of a function $f$, the set of variable index $i$ such that $f[i\leftarrow 0] \neq f[i\leftarrow 1]$.
A variable that does not belong to the support, is said to be a non-support variable or useless variable.
Thus, the $i$-th variable of $f$ is useless iff $f[i\leftarrow 0] = f[i\leftarrow 1]$.

\section{Reduced Ordered Binary Decision Diagram (ROBDD) and Canonicity}

\paragraph{Definition of Binary Decision Diagram (BDD)\\}

A Reduced Ordered Binary Decision Diagram is a directed acyclic graph $(V\cup T, \Psi \cup E)$ representing a vector of Boolean functions $F=(f_1, ..., f_k)$ other an infinite set of variables.
Nodes are partitioned into two sets : the set of internal nodes $V$ and the set of terminal nodes $T$.
Every internal node $v\in V$ has one field $var$, which represent the index of a variable and two outgoing edges respectively denoted $if0$ and $if1$.
When using the "output inverter" variant, there is only one terminal called 0, which represent the functions which always return 0.
Arcs are partitioned into two sets : the set of root arcs $\Psi$ and the set of internal arcs $E$.
There is exactly $k$ root arcs, a root arc is denoted $\Psi_i$ with $0\leq i < k$, informally, $\Psi_i$ is the root of the ROBDD representing $f_i$.
Every arc has an inversion field $neg \in \B$ and a destination node denoted $node$.

%add beautiful draw (with \psi arcs)$

We denote $\phi(node)$ the semantic of the node $node$ and $\psi(arc)$ the semantic of the arc $arc$ as follow:\begin{itemize}
\item $\forall i, f_i = \psi(\Psi_i)$
\item $\forall arc \in \Psi \cup E, \psi(arc) = arc.neg \oplus \phi(arc.node)$
\item $\phi(0 \in T) = 0$
\item $\forall node \in V, \phi(node) = \shannon{node.var}{\psi(node.if0)}{\psi(node.if1)}$
\end{itemize}

\paragraph{Definition of Reduced Ordered BDD (ROBDD)\\}
A BDD is said \texttt{ordered} if (1) $\forall v\in V$, $v.then.node \in V \Rightarrow v.var > v.if1.node.var$ and $v.else.node \in V \Rightarrow v.var > v.if0.node.var$.
%define an order over variables

A BDD is said \texttt{reduced} if (2) $\forall v\in V, v.if0 \neq v.if1$ and (3) every node has an in-degree strictly positive.

\paragraph{Theorem : ROBDD are canonical\\}

Let consider a ROBDD $G$ representing $F=(f_1, ..., f_n)$ over a set of n variables $x_n < x_{n-1} < ... < x_1$. Then, for every nodes $v_1, v_2 \in G$, $\phi(v_1) = \phi(v_2) \Leftrightarrow v_1 = v_2$.

A proof a proof of this theorem, is available in the review of Somenzi et al.\cite{Somenzi1999}.

\subsection{Effective construction}
In practice one does not build the decision tree and then reduces it.
Rather, BDDs are created starting from the BDDs for the constants and the variables by application of the usual Boolean connectives and are kept reduced at all times.
At the same time several functions are represented by one multi-rooted diagram.
Indeed, each node of a BDD has a function associated with it.
If we have several functions, they will have subfunctions in common.
For instance, if we have $f(x_0, x_1, x_2, x_3) = \shannon{x_1}{x_2}{x_3}$ and $f(x_0, x_1, x_2, x_3) = \shannon{\lnot x_1}{x_2}{x_3}$. As a special case two equivalent functions are represented by the same BDD (not just two identical BDDs).
This approach makes equivalence check a constant-time operation.
Its implementation is usually based on a dictionary of all BDDs nodes in existence in an application.
This dictionary is called the \textit{unique table}.
Operations that build BDDs start from the bottom (the constant nodes) and proceed up to the function nodes.
Whenever an operation needs to add to a BDD that it is building, it knows already the two nodes (say $f_1$ and $f_0$ represented by some identifier (usually implemented as pointers)) that going to be the new node's children and the decision variable $v$ so it just has to check if the node $(v, f_1, f_0)$ already exist and if so return its identifier and if not generate a new identifier and return it.
Doing so, the equivalence check is reduced to pointer comparison.

\paragraph{Operator \texttt{CONS}\\}


Pseudo-code for dynamic construction of unique nodes.

\begin{lstlisting}
let cons var if0(*else arc*) if1(*then arc*) =
  if if0 = if1
  then if0
  else
  (
    if0' = {neg = 0; node = if0.node}
    if1' = {neg = if0.neg $\oplus$ if1.neg; node = if1.node}
    mynode = {var; then = if0'; else = if1'}
    myid = if mynode in $\mathit{unique~table}$
      then "mynode's identifier"
      else
      (
        store mynode in $\mathtt{unique table}$;
        "mynode's identifier"
      )
    {neg = if0.neg; node = myid}
  )
\end{lstlisting}

\section{Introduction of Generalized Reduction of Ordered Binary Decision Diagram (GroBdd)}

\subsection{Motivation}

In one hand, a ROBDD can be understood as an automaton recognizing a language compose of binary words.
On the other hand, a ROBDD can be understood as a logic circuit with limited conciseness.
By limited conciseness, we mean that their is functions which have a polynomial representation using an And-Inverter-Graph (AIG, i.e. a logic circuit composed of \texttt{AND} and \texttt{NOT} gates), but only exponential representation when using ROBDD.
For example, the integer multiplication has a quadratic AIG representing it, however, it is proven \cite{Bryant1986} that a ROBDD representing it has at least an exponential number of nodes (thus, of gates).

The "output inverter" variant, by adding expressiveness to edges, improves the conciseness.
We want to go further in this approach by allowing more complex transformation on edges while maintaining canonicity.
Such transformation can disturb variables' order of evaluation, allowing to represent "simple" decision processes in more concise way.
Furthermore, some transformation (within the range of transformation allowed) could have their complexity drastically reduced.
For example, using the "output inverter" variant, the complementation's time and space complexity which goes from linear in the number of node to constant.

Three set of transformation that would be of great interest are the "useless variable extraction" (or "U extract" for short), the "inputs inverters" and "1-predictions extraction" (or "X extract" for short).


The "U extract" variant allows to introduce useless variables, thus ensure that the function represented by any node, does not have useless variable.
Therefore, it sets an upper bound on the number of node of arity $n$ to $2^{2^n}$ (this upper bound is not reached).
Furthermore, it allows to "copy" functions at (almost) no cost as the expression $f(x_1, x_3, x_5, x_7)$ and $f(x_0, x_1, x_3, x_5)$ are represented using the same structure.


The "inputs inverters" variant would allow to complement inputs on any edge.
The reduction rules would ensure that there is at most $2^{2^n-n}$ nodes of arity $n$ (this upper bound is not reached).
However, introducing this variant breaks the canonicity, therefore, while working on a generalization of it, we do not discuss it further in this report.

We define a 1-prediction as follow:
Let $f$ be a Boolean function of arity $n$, $i$ be an integer ($0\leq i < n$), $x$ and $y$ be Booleans, we say that the function $f$ admit a 1-prediction $(i, x, y)$ iff $f[i\leftarrow x] = y$.
The "X extract" variant, by allowing to extract 1-predictions, represents a generalization of ZBDD (Zero Suppressed Binary Decision Diagram), thus, allows to efficiently represent sparse function.
This variant is compatible with the "output inverter" variant, however it over-complexifies the reduction rules, therefore, while reformulating reduction rules in a simpler way, we do not discuss it further in this report.


The Generalized Reduction of Ordered Binary Decision Diagram (GroBdd) is a framework that aims at providing examples of such reduction rules and boundaries on future reduction rules that would fit inside this framework.
The remaining of this Section is organized as follows. First, we formally define GroBdds, then we present a set of properties that the transformation must have and some implications.

\subsection{Initial definition of GroBdd}

A GroBdd is very similar to an actual ROBDD, the two main differences being that (1) it represents a vector of Boolean functions with a finite number of variables possibly of different arity and (2) on every edge their is a transformation (the "output inverter" is an example of such transformations").

A Reduced Ordered Binary Decision Diagram is a directed acyclic graph $(V\cup T, \Psi \cup E)$ representing a vector of Boolean functions $F=(f_1, ..., f_k)$.
Nodes are partitioned into two sets : the set of internal nodes $V$ and the set of terminal nodes $T$.
Every internal node $v\in V$ has two outgoing edges respectively denoted $if0$ and $if1$.
Every internal node $v\in V$ has a field $index$ which represent a unique identifier associated to each node.
Arcs are partitioned into two sets : the set of root arcs $\Psi$ and the set of internal arcs $E$.
There is exactly $k$ root arcs, a root arc is denoted $\Psi_i$ with $0\leq i < k$, informally, $\Psi_i$ is the root of the GroBdd representing $f_i$.
Every arc has a transformation descriptor field $\gamma$ and a destination node denoted $node$.

%add beautiful draw (with \psi arcs)$
We denote $\rho(\gamma) : \F_n \longrightarrow F_m$ the semantic interpretation of the transformation descriptor $\gamma$.
We define $\phi(node)$ the semantic of the node $node$ and $\psi(arc)$ the semantic of the arc $arc$ as follow:\begin{itemize}
\item $\forall i, f_i = \psi(\Psi_i)$
\item $\forall arc \in \Psi \cup E, \psi(arc) = \rho(arc.\gamma)(\phi(arc.node))$
\item $\forall node \in V, \phi(node) = \psi(node.if0) \star \psi(node.if1)$
\end{itemize}
We assume the function $\phi$ defined on all terminals $T$ (we always assume, all terminal to have a different interpretation through $\phi$).

\subsection{Transformation Descriptor Set (TDS)}

We denote $\Y$ the set of all transformation descriptor.
We assumme defined $\rho$ the semantical interpretation of transformation descriptors, $\forall \gamma, \exists n, m \in\N, \rho(\gamma) \in \F_n \rightarrow \F_m$ (with $n\leq m$).
In this section, we make the list of properties that the TDS must ensure to be correct.

\subsubsection{Canonical}
\[\forall \gamma, \gamma' \in \Y, \left( \gamma = \gamma' \right) \Leftrightarrow \left( \rho(\gamma) = \rho(\gamma') \right) \]
We denote $\Y_{n, m} = \{ \gamma \in \Y ~|~ \rho(\gamma) \in \F_n \longrightarrow \F_m \}$, and $\Y_{n,*} = \bigcup_{m\leq n} \Y_{n, m}$ and $\Y_{*, m} = \bigcup_{n \geq m} \Y_{n, m}$.

\subsubsection{Separable}
\[\forall \gamma \in \Y_{n, m}, \exists! \vartriangle_\gamma \in \B^m \rightarrow \B^n, \triangledown_\gamma \in \B^m \rightarrow \B \rightarrow \B,\]
\[\forall f\in \F_n, \forall x \in \B^m, \rho(\gamma)(f)(x) = \triangledown(x, f(\vartriangle x))\]
This constraint allows any transformation to be represented as circuit which can be wrapped around the function.
This constraint enforces transformations to be local.
The function $\vartriangle$ is called the pre-process, and the function $\triangledown$ is called the post-process.

\subsubsection{Composable (definition of \texttt{C})}
\[\forall \gamma \in \Y_{n, m}, \gamma' \in \Y_{m, l}, \exists \gamma'' \in \Y_{n, l}, \rho(\gamma') \circ 
\rho(\gamma) = \rho(\gamma'')\]
This constraint enforces $\Y_{n, n}$ to be stable by composition.
Furthermore, it exists an algorithm $\mathtt{C} : \Y_{n, m} \rightarrow \Y_{m, l} \rightarrow \Y_{n, l}$, such that:
\[\forall \gamma \in \Y_{n, m}, \gamma' \in \Y_{m, l}, \rho(\gamma') \circ \rho(\gamma) = \rho(\mathtt{C}(\gamma, \gamma'))\]
For convenience, we denote $\gamma' \circ \gamma = \mathtt{C}(\gamma, \gamma')$.

\subsubsection{Decomposable (definition of \texttt{A} and \texttt{S})}

For all $n\in\N$, we define $A_n = \Y_{n, n}$ the set of asymmetric transformations.
For all $n, m\in\N$, it exists $S_{n, m} \subset \Y_{n, m}$ a set of transformations such that $\forall \gamma \in \Y_{n, m}, \exists a \in A_m, \exists! s \in S_{n, m},  \gamma = a \circ s$.
The set $S_{n, m}$ is called the set of symmetric transformation.
%Consequence : $S_{n, n} = \{ Id_n = \F_n \rightarrow \F_n \}$.

\paragraph{definition : S-free\\}
A Boolean function $f\in\F_m$ is said S-free, iff
\[\forall s \in S_{n, m}, \forall g \in \F_n, f = \rho(s)(g) \Rightarrow \rho(s) = Id\]

\paragraph{constraint : S-uniqueness\\}
\[\forall f\in\F_n, f'\in\F_{n'}, s\in S_{n, m}, s'\in S_{n', m}, \rho(s)(f) = \rho(s')(f') \Rightarrow (s = s') \land (f = f')\]

\paragraph{definition : A-equivalent\\}
Two Boolean functions $f, g\in\F_n$ are said A-equivalent, iff $\exists a\in A_n, f = \rho(a)(g)$.
This relation is an equivalence relation (i.e. reflexive, symmetric, transitive) denote $\sim_A$.

\paragraph{definition : A-invariant free\\}
A Boolean function $f\in\F_n$ is said A-invariant free, iff $\forall a, a'\in A_n, \rho(a)(f) \neq \rho(a')(f)$.

\paragraph{constraint : S-free implies A-invariant free\\}
For all function $f$, if $f$ is S-free, then $f$ is A-invariant free.

\paragraph{definition : A-reduced set of function\\}
Let $X = \{x_1, x_2, \dots, x_n\}$ be a set of Boolean functions.
The set $X$ is said A-reduced iff $\forall x_i, x_j \in X, (x_i \sim_A x_j) \Rightarrow (x_i = x_j)$.

\paragraph{definition : $\I_n$\\}
For all $n\in\N$, we denote $\I_n$ the set of identifiers corresponding to node representing functions of arity $n$.

\paragraph{definition : $\Ynode$\\}
A $\Ynode_{l, m, n}$ is a quadruple $(\gamma_0, I_0, \gamma_1, I_1) \in \Y_{l, n} \times \I_l \times \Y_{m, n} \times \I_m$. Let $v$ be a $\Ynode$, we denote $v.\gamma_0$ (respectively $v.I_0$, $v.\gamma_1$ and $v.I_1$) the first (respectively second, third and fourth) component of $v$.
\begin{itemize}
\item For all $\Ynode$ $v$, we always assume that functions $\phi(v.I_0)$ and $\phi(v.I_1)$ are \texttt{S}-free.
\item We always assume the set $X = \{\phi(v.I_0) ~|~ v \in\Ynode\} \cup \{\phi(v.I_1) ~|~ v\in\Ynode\}$ to be \texttt{A-reduced}
\end{itemize}
We extend the definition of $\phi$, with : for all $\Ynode$ $v$, $\phi(v) = \rho(v.\gamma_0)(\phi(v.I_0)) \star \rho(v.\gamma_1)(\phi(v.I_1))$.

\paragraph{constraint : terminal nodes are S-free and A-reduced (definition of $\mathtt{E}_0$)}
For all terminal node $t \in T$, $t$ is S-free.
Furthermore, the set $\{\phi(t) ~|~ t\in T\}$ is A-reduced.
Moreover, we define the function $\mathtt{E}_0$ such $\forall b\in\F_0, \exists \gamma\in\Y_{0, 0}, \exists t\in T, \mathtt{E}_0(b) = \{\gamma = \gamma, node = I_t\}$ and $\psi(\mathtt{E}_0(b)) = b$.


\subsubsection{Buildable (definition of \texttt{B})}

Let $X$ be a function, we denote $I_X$ the identifier of an hypothetical node whose semantic interpretation is $X$.

We define \texttt{B} an algorithm over $\Y$ which respect the signature:
\begin{lstlisting}
$\mathtt{B} : \Y_{n_0, m} \times \I_{n_0} \longrightarrow \Y_{n_1, m} \times \I_{n_1} \longrightarrow$
  | ConsNode $\Y_{n', m} \times (\Y_{n_x, n'} \times \I_{n_x}) \times (\Y_{n_y, n'} \times \I_{n_y})$
  | Merge $\Y_{n_z, m} \times \I_{n_z}$
\end{lstlisting}
(with $x, y, z \in \{0, 1\}$) \\
Furthermore, for all $(\gamma_g, I_g, \gamma_h, I_h) \in \Y_{n_0, m} \times \I_{n_0} \times \Y_{n_1, m} \times \I_{n_1}$, 
\[ \texttt{B}(\gamma_g, I_g, \gamma_h, I_h) = \texttt{ConsNode} (\gamma, (\gamma', I_X), (\gamma'', I_Y)) \Rightarrow f = \rho\left(\gamma\right) \left(\rho\left(\gamma'\right)(X) \star \rho\left(\gamma''\right)(Y)\right)\]
\[ \texttt{B}(\gamma_g, I_g, \gamma_h, I_h) = \texttt{Merge} (\gamma''', I_Z) \Rightarrow f = \rho(\gamma''')(Z) \]
(with $X, Y, Z \in\{g, h\}$ and $f = \rho(\gamma_g)(g) \star \rho(\gamma_h)(y)$)

\paragraph{definition : a node is \texttt{B}-stable\\}
Let $G$ be a GroBdd, we denote $v$ an internal node of $G$.
We denote $\gamma_0 = v.if0.\gamma, I_0 = v.if0.node, \gamma_1 = v.if1.\gamma$ and $I_1 = v.if1.node$.
The node $v$ is said B-stable iff $\mathtt{B}(\gamma_0, I_0, \gamma_1, I_1) = \mathtt{ConsNode}(Id, (\gamma_0, I_0), (\gamma_1, I_1))$.

\paragraph{constraint : \texttt{B} is \texttt{B}-stable\\}
\[\forall \gamma_f, I_f, \gamma_g, I_g, \mathtt{B}(\gamma_f, I_f, \gamma_g, I_g) = \mathtt{ConsNode}(\gamma, (\gamma_0, I_0), (\gamma_1, I_1))\]
\[\Rightarrow \mathtt{B}(\gamma_0, I_0, \gamma_1, I_1) = \mathtt{ConsNode}(Id, (\gamma_0, I_0), (\gamma_1, I_1))\]
Informally, when B returns a node, this node is \texttt{B}-stable.

\paragraph{constraint : $\Ynode$ are \texttt{B}-stable}
\begin{enumerate}
\item We assume all $\Ynode$ $v$ to be \texttt{B}-stable
\[\mathtt{B}(v.\gamma_0, v.I_0, v.\gamma_1, v.I_1) = \mathtt{ConsNode}(Id, (v.\gamma_0, v.I_0), (v.\gamma_1, v.I_1))\]
\end{enumerate}

\paragraph{constraint : B is S-free preserving\\}
The algorithm \texttt{B} is said S-free preserving iff for all $\Ynode$ $v$, $\phi(v)$ is S-free.

\paragraph{constraint : B is A-reduction preserving\\}
The algorithm \texttt{B} is said A-reduction preserving iff
\[\forall v, w \in\Ynode, \phi(v) \sim_A \phi(w) \Rightarrow v = w\]

\subsection{Reduction Rules}
We define a GroBdd model as the triple $(\Y, \mathtt{C}, \mathtt{B})$.
A valid model must satisfy all the previously mentioned constraints.

In addition to the previous constraints, we define two reduction rules:\begin{enumerate}
\item The syntactical reduction : all sub-graphs are different up to graph-isomorphism (i.e. all identical sub-graphs are merged)
\item The local semantic reduction : all internal node $v\in V$ is \texttt{B}-stable.
\item All node has at least one incoming arc.
A GroBdd is said reduced if it satisfies the reduction rules.
\end{enumerate}
In this section we prove:\begin{enumerate}
\item For all vector of Boolean function $F$ it exists a reduced GroBdd $G$ representing it.
\item A reduced GroBdd $G$ is semi-canonical, defined as :\begin{enumerate}
\item For all node $v\in V$, $\phi(v)$ is S-free.
\item The set $X = \{\phi(v_1), \dots, \phi(v_N)\}$ representing the set of the semantic interpretation of the set of internal nodes $V$ is A-reduced.
\item $\forall (\gamma, I, \gamma', I') \in (\Y_{n, m} \times \I_n)^2, \psi(\{\gamma = \gamma, node = I\}) = \psi(\{\gamma = \gamma', node = I'\}) \Rightarrow (\gamma, I) = (\gamma', I')$ (with $I$ and $I'$ being indexes of nodes in $G$).
\end{enumerate}
\item Between two reduced GroBdd $G$ and $G'$ representing the same vector of Boolean functions $F$, it exists a one-to-one mapping $\sigma : V \longrightarrow V'$ such that $\forall v, v' \in V \times V', \sigma(v) = v' \Rightarrow (\exists a \in A_{*}, \phi(v) = \rho(a)(\phi(v'))$.
\end{enumerate}

\subsubsection{Additional procedures}

\paragraph{The \texttt{Cons} procedure\\}
We define the \texttt{Cons} procedure as follow.
Let $G$ be a GroBdd and $F$ be its vector of root arcs of size $k$.\\
Let $i$ and $j$ be indexes of this vector.
We denote $\gamma_i = \Psi_i.\gamma$, $\gamma_j = \Psi_j.\gamma$ and $I_i = \Psi_i.node$, $I_j = \Psi_j.node$.
\begin{itemize}
\item If \texttt{B}($\gamma_g$, $I_g$, $\gamma_h$, $I_h$) = \texttt{ConsNode} ($\gamma$, ($\gamma'$, $I_X$), ($\gamma''$, $I_Y$)). We define the node $N = \{if0 = \{\gamma = \gamma', node = I_X\}, if1 = \{\gamma = \gamma'', nodes = I_Y\}\}$.\begin{itemize}
\item If the node $N$ already exists in $G$, we retrieve its identifier $I$, we define $G'$ as a copy of $G$ with a new root arc $\Psi_k = \{\gamma = \gamma, node = I\}$
\item Otherwise, we define $G'$ as a copy of $G$ with add $N$ to the list of nodes of $G'$ and create it a new identifier $I$, we add a new root arc $\Psi_k = \{\gamma = \gamma, node = I\}$.
\end{itemize}
\item Otherwise, \texttt{B}($\gamma_g$, $I_g$, $\gamma_h$, $I_h$) = \texttt{Merge} ($\gamma$, $I_Z$). We define $G'$ as a copy of $G$ with a new root arc $\Psi_k = \{\gamma = \gamma''', node = I_Z\}$.
\end{itemize}

\paragraph{The \texttt{Remove} procedure\\}
We define the \texttt{Remove} procedure as follow.
Let $G$ be a GroBdd and $F$ be its vector of root arc of size $k$.\\
Let $i$ be an index of this vector
We define $G'$ as a copy of $G$ with its vector of root arc $F' = (\Psi_1, \dots, \Psi_{i-1}, \Psi_{i+1}, \dots, \Psi_n)$.
In an iterative process, we remove nodes which have no incoming arc, until all nodes have at least one incoming arc (in order to satisfy the third reduction rule).
As $G'$ is a subset of $G$, thus, $G'$ satisfies the first and second reduction rule.

\paragraph{The \texttt{Reduction} procedure\\}
Let $G$ be a GroBdd and $F$ be its vector of root arcs $F$.
Using an iterative process, we remove nodes which have no incoming arc, until all nodes have at least one incoming arc (satisfying the third reduction rules).
The \texttt{Reduction} procedure consist in going through the GroBdd $G$ (starting with nodes with the smallest depth), applying the \texttt{Cons} procedure on each node creating a new GroBdd $G'$.
The GroBdd $G'$ is by construction equivalent to $G$, however, the GroBdd $G'$ satisfies all three reduction rules.

\paragraph{The \texttt{Merge} procedure\\}
We define the \texttt{Merge} procedure as follow.
Let $G$ and $G'$ be two GroBdds (based on the same GroBdd model).
We define $G''$ a GroBdd which is the union of both GroBdd.
We define $F'' = (\Psi_1, \dots, \Psi_n, \Psi'_1, \dots, \Psi'_{n'})$.
Due to possible conflicts on identifiers, we re-generate identifiers of the nodes in $G''$.
Finally, we apply the \texttt{Reduction} procedure on $G''$.

\subsubsection{Existence}
We inductively define the procedure \texttt{E} with:\begin{itemize}
\item $\forall b\in\F_0, \texttt{E}(b) = \texttt{E}_0(b)$
\item
Let $f$ be a Boolean function of arity $n$ (with $n \geq 1$).
Let $G$ be a GroBdd representing functions $f_0$ (the negative restriction of $f$ according to its first variable) and $f_1$ (the positive restriction of $f$ according to its first variable.) by using the procedure \texttt{E} on $f_0$ and $f_1$.
Let $G'$ be the output of the \texttt{Cons} procedure on $G$, in order to create $f = f_0 \star f_1$ (expansion theorem).\\
$E(f) = G'$
The GroBdd $G'$ satisfies the reduction rules:\begin{itemize}
\item If no node is created, the proof is straightforward.
\item If a node is created, this node is syntactically unique by definition of \texttt{Cons} and is \texttt{B}-stable  (as \texttt{B} is \texttt{B}-stable)
\end{itemize}
\end{itemize}

By construction, the procedure \texttt{E} (generalized to accept a vector of function as input) returns a GroBdd satisfying the reduction rules.

\subsubsection{Semi-Canonical}

Let $G$ be a reduced GroBdd.

\paragraph{S-free and A-reduced}
For all node $v\in V$, we denote $h(v) = max(h(v.if0.node), h(v.if1.node))$ with $\forall t\in T, h(t) = 0$.
For all $n\in\N$, we define $V_n = \{v\in V ~|~ h(v) \leq n\}$
For all $n\in\N$, we define the recurrence hypothesis $H(n)$ :\begin{itemize}
\item For all $v\in V_n$, $\phi(v)$ is S-free.
\item The set of Boolean function $X = \{\phi(v) ~|~ v\in V_n\}$ is A-reduced.
\end{itemize}

\subparagraph{Initialization}
We prove $H(0)$ using the constraints that (1) terminals are S-free and (2) the set of terminal nodes is A-reduced.

\subparagraph{Induction}
Let $n\in\N$, we assume $\forall k\leq n H(k)$.
Let $v$ be a node of depth $n+1$, thus the depth of $v.if0.node$ and $v.if1.node$ is lower than $n$ (we can apply the recurrence hypothesis).
Therefore, the quadruple $\bar{v} = (v.if0.\gamma, v.if0.node, v.if1.\gamma, v.if1.node)$ is a $\Ynode$.
Thus, using the constraints that \texttt{B} is S-free preserving, we prove that $\phi(v) = \phi(\bar{v})$ is S-free.
Let $v'$ be a node of depth $k\leq n+1$, we can prove that the quadruple $\bar{v'} = (v'.if0.\gamma, v'.if0.node, v'.if1.\gamma, v'.if1.node)$ is a $\Ynode$.
Therefore, we can use the constraint that \texttt{B} is A-reduction preserving to prove that $\phi(\bar{v}) \sim_A \phi(\bar{v'}) \Rightarrow \phi(\bar{v}) = \phi(\bar{v'})$
However, $\phi(v) = \phi(\bar{v})$ and $\phi(v') = \phi(\bar{v'})$
Thus, $\forall v, w \in V_{n+1}, \phi(v) \sim_A \phi(v') \Rightarrow \phi(v) = \phi(v')$.
Thus, the set of Boolean function $X = \{\phi(v) ~|~ v\in V_{n+1}\}$ is A-reduced.
Therefore $(land_{k\leq n} H(k) \Rightarrow H(n+1)$.

Using the strong recurrence theorem, we prove that $\forall n\in\N, H(n)$.
Therefore proving properties (2.a) "all nodes are S-free" and (2.b) "the set $X = \{\phi(v_1), \dots, \phi(v_N)\}$ is A-reduced".

\paragraph{Semantic Reduction}
We prove the property "$\forall (\gamma, I, \gamma', I') \in (\Y_{n, m} \times \I_n)^2, \psi(\{\gamma = \gamma, node = I\}) = \psi(\{\gamma = \gamma', node = I'\}) \Rightarrow (\gamma, I) = (\gamma', I')$ (with $I$ and $I'$ being indexes of nodes in $G$)" by induction on $n\in\N$ the arity of $f = \psi(\{\gamma = \gamma, node = I\})$.

\subparagraph{Initialization}
The induction property holds for $n = 0$:\\
Let $f\in\F_0$, we assume it exists a quadruple $(\gamma, I, \gamma', I') \in (\Y_{n, m} \times \I_n)^2$ such that $f = \psi(\{\gamma = \gamma, node = I\}) = \psi(\{\gamma = \gamma', node = I'\})$.
We decompose $\gamma$ and $\gamma'$ to their symmetric and asymmetric components: $\gamma = s \circ a$ and $\gamma' = s' \circ a'$.
Using the S-uniqueness constraint, on $f = \rho(s)(\rho(a)(\phi(I))) = \rho(s')(\rho(a')(\phi(I')))$, we have $s = s'$ and $\rho(a)(\phi(I)) = \rho(a')(\phi(I'))$.
Therefore, $\phi(I) \sim_A \phi(I')$, however, we proved that the set of the semantic interpretations of the nodes is A-reduced, thus $\phi(I) = \phi(I')$
However, the only node representing function of arity 0 are terminal nodes, therefore $I = I'$.

\subparagraph{Induction}
Let $k\in\N$, we assume the induction property holds for all $n\leq k$, let prove it holds for $n = k+1$.
Let $f$ be a Boolean function, we assume it exists a quadruple $(\gamma, I, \gamma', I') \in (\Y_{n, m} \times \I_n)^2$ such that $f = \psi(\{\gamma = \gamma, node = I\}) = \psi(\{\gamma = \gamma', node = I'\})$.
We decompose $\gamma$ and $\gamma'$ to their symmetric and asymmetric components: $\gamma = s \circ a$ and $\gamma' = s' \circ a'$.
Using the S-uniqueness constraint, on $f = \rho(s)(\rho(a)(\phi(I))) = \rho(s')(\rho(a')(\phi(I')))$, we have $s = s'$ and $\rho(a)(\phi(I)) = \rho(a')(\phi(I'))$.
Therefore, $\phi(I) \sim_A \phi(I')$, however, we proved that the set of the semantic interpretations of the nodes is A-reduced, thus $\phi(I) = \phi(I')$
Using the induction hypothesis (as $\phi(I)$ as an arity strictly smaller than $k+1$, thus smaller than $k$), we deduce that $I = I'$.

Therefore, applying the strong induction theorem, we prove the property (2.c).

\subsubsection{Canonical modulo graph-isomorphism and A-equivalence}
In order to prove that "Between two reduced GroBdd $G$ and $G'$ representing the same vector of Boolean functions $F$, it exists a one-to-one mapping $\sigma : V \longrightarrow V'$ such that $\forall v, v' \in V \times V', \sigma(v) = v' \Rightarrow (\exists a \in A_{*}, \phi(v) = \rho(a)(\phi(v'))$", we start by (1) proving that within the \texttt{Merge} procedure, each node is replace by an A-equivalent one then (2) using the \texttt{Merge} procedure without re-generating the identifiers of the nodes of $G$ and using the property (2.c), we prove that the nodes of $G'$ collapse on the nodes of $G$ during the \texttt{Reduction} procedure, providing a one-to-one mapping.
Details of this proof are cumbersome and not of great interest.


\subsection{Conclusion}

In this section, we introduced the concept of Generalized Reduction of Ordered Binary Decision Diagrams (GroBdd) and provided a set of necessary conditions and reduction rules, which guarantee the reduced structure to be semi-canonical. This approach still allows to perform the equality test in a reasonable amount of time: proportional to the size of the transformation descriptor, which (for practical reasons) should be polynomial in the arity of the post-transformation function.
In the remaining of this report (if not mentioned otherwise), a GroBdd is to be assumed reduced.
In the next section, we will introduce the "useless variable extraction" variant (or "U-extract" for short) as being a simple model (called "U") in the GroBdd formalism that we just introduced.

\section{Pattern extraction : useless variables}
\begin{figure}
\centering
%\caption{BDD with Extraction of useless variables}
\includeframe{3}{1}{}{draws.pdf}
\caption{Same BDD as in Figure~\ref{draws1}, when detecting and removing useless variables. Each red rectangle contain the support set of each arc's function.}
\label{draws3}
\end{figure}


\begin{figure}
\centering
%\caption{BDD with Complemented Arcs reduction \& Extraction of useless variables}
\includeframe{4}{1}{}{draws.pdf}
\caption{Same BDD as in Figure~\ref{draws2} and~\ref{draws3}, with both additional reduction rules : complemented arcs and extraction of useless variables.}
\label{draws4}
\end{figure}

\subsection{Motivation}
We may notice that the respective representations of $f_1 = f(x_{i_1}, ..., x_{i_n})$ ($i_1 < ... < i_n$) and $f_2 = f(x_{j_1}, ..., x_{j_n})$ ($j_1 < ... < j_n$) are very similar.
The only difference being the values of the $var$ field of each nodes within the representation of $f$.
This suggest the possibility of actually using the same sub-graph to represent $f$, $f_1$ and $f_2$.


Suppose we have a BDD representing $f$, then in order to represent $f_1$ we just have to remember which variable are in the support of $f$ (the relative order of variables in the support does not change).
In this attribute, we will store the support set in the $coreduce$ field of arcs.

Removing useless variables slightly complexify (e.g. we have to add an other reduction rule) the manipulation of BDDs, but has three advantages:\begin{itemize}
\item reduce memory usage (in some cases there is an exponential gain, but on most cases its less significant).
\item copying a function (if relative order of variables is unchanged) can be performed in constant time.
\item checking $g = f$ modulo their useless variables -when having $g$ and $f$- can be performed in constant time (not very useful).
\end{itemize}

\subsection{Proof of Canonicity}

We define the following reductions rules:\begin{itemize}
  \item $\forall v\in V, v.then.coreduce \cup v.else.coreduce = \{0, ..., n\}$
  \item $\forall v\in V\cup T, \phi(v)$ has no useless variable
\end{itemize}

For every function $f$, we denote $\tilde{f}$ the restriction of $f$ to its support (maintaining the relative order of the remaining variables).

\paragraph{Existence}
Let $f\in\B^n\rightarrow\B$ be a Boolean Function. We recursively build a valid representation $R(f)$ of $f$ which verify the reduction rules:\begin{itemize}
  \item $R((x_1, ..., x_n) \rightarrow b) = arc(coreduce = \emptyset, node = 1)$, where $b\in\B$
  \item $R(f) = $\begin{itemize}
    \item We denote $S=\{i_1 < ... < i_k\}$ the support set of $f$.
    \item $R(f) = arc(coreduce = S, node = node(then = R(\tilde{f}[0\leftarrow 1]), else = R(\tilde{f}[0\leftarrow 0])))$
  \end{itemize}
\end{itemize}

\paragraph{Uniqueness}
We prove canonicity by induction on $n$ the arity of the represented function.
\subparagraph{Initialization}
Let $R$ be a representative of a function of arity 0. We consider the root arc $a$, so $a.coreduce = \emptyset$ (the only set of cardinality lower than zero). However the \texttt{in-arity} of $\emptyset$ is 0, so $a.node$ represent a constant function. Hence either $R = arc(coreduce = \emptyset, node = 0)$ representative of the constant function 0 or $R = arc(coreduce = \emptyset, node = 1)$ representative of the constant function 1.
\subparagraph{Induction}
Assuming that the hypothesis holds for every $0\leq k\leq n$.
Let $R$ be a representative of $f$, we denote $a$ its root arc.
\begin{itemize}
  \item We assume that $a.coreduce \neq \{0, ..., n\}$. Then the arity of $g = \phi(a.node)$ is lower strictly lower than $n$. However $g$ has a unique representation (induction hypothesis) and $g$ has no useless variable (because of the reduction rules on applied on node $a.node$). So the only useless variable in $f$ are the one that does not appear in $a.coreduce$. Therefore $R$ is unique.
  \item We assume that $a.coreduce = \{0, ..., n\}$. We denote $a_1$ (respectively $a_0$) the root arc of the representation (unique by induction hypothesis) of $f_1 = \psi(a.node.then)$ (respectively $f_0 = \psi(a.node.else)$).\begin{itemize}
    \item We assume that $f_1 = f_0$ then $a_1 = a_0$ then either induce that $0\not\in a.coreduce$ (which induce a contradiction with $S=\{0, ..., n\}$) or R does not satisfies the reduction rules.
    \item Therefore $f_1\neq f_0$.\begin{itemize}
      \item We assume that $a_1.coreduce~\cup~a_0.coreduce \neq \{0, ..., n-1\}$. Then it exist $0\leq i\leq n-1$ such that $x_i$ is useless for both $f_1$ and $f_0$. Hence $i+1$ is useless for $f$. So R does not satisfies the reduction rules.
      \item Therefore $a_1.coreduce~\cup~a_0.coreduce = \{0, ..., n-1\}$. Then $a = arc ( coreduce = \{0, ..., n\},~node = node(then = a_1,~else = a_0)$. Therefore $R$ is unique.
    \end{itemize}
  \end{itemize}
\end{itemize}

\subsection{Reduction in construction}
Moreover, as we already define the main algorithm for construction, we just have to write the specific sub-routines:
\begin{lstlisting}
RDT-consensus($then$, $else$, cmp){
  if (cmp = 0) & $then.coreduce$ = $else.coreduce$ then{
    we denote $\{i_1 < ... < i_k\} = then.coreduce$
    Solved arc(then = $\{i_1+1 < ... < i_k+1\}$, node = then.node)
  }else{
    we denote $U = \{i_1 < ... < i_k\} = then.coreduce \cup else.coreduce$
    we denote $A = \{a_1 < ... < a_l\}$ the indexes of $then.coreduce$ in $U$.
    we denote $B = \{b_1 < ... < b_m\}$ the indexes of $else.coreduce$ in $U$.
    Partial (coreduce = $\{0, i_1+1, ..., i_k+1\}$, reduce = node(then = arc(coreduce = $A$, node = $then.node$), else = arc(coreduce = $B$, node = $else.node$) ) )
  }
}  
\end{lstlisting}
\begin{lstlisting}
compose$(\{i_1 < ... < i_n\}$, arc(coreduce = $\{j_1 < ... < j_k\}$, node = node){
  return arc(coreduce = $\{i_{j_1} < ... < i_{j_k}\}$, node = node)
}
\end{lstlisting}

\subsection{Reduction in operators}
Moreover, as we already define the main algorithm for computing AND, we just have to write the specific sub-routines:
\begin{lstlisting}
and-unpack(reduced-problem){
  return (reduced-problem.arcX, reduced-problem.arcY)
}
\end{lstlisting}
\begin{lstlisting}
and-solver(arcX, arcY){
  if (terminal cases){
    return result //removing useless variables does not add terminal cases
  }else{
    we denote $U = \{i_1 < ... < i_k\} = then.coreduce \cup else.coreduce$
    we denote $A = \{a_1 < ... < a_l\}$ the indexes of $then.coreduce$ in $U$.
    we denote $B = \{b_1 < ... < b_m\}$ the indexes of $else.coreduce$ in $U$.
    if arcX $\leq$ arcY
    then{
      Partial (coreduce = U, subproblem = (arcX = arc(coreduce = A, node = arcX.node), arcY = arc(coreduce = B, node = arcY.node)))
    }else{
      Partial (coreduce = U, subproblem = (arcY = arc(coreduce = A, node = arcX.node), arcX = arc(coreduce = B, node = arcY.node)))
    }
  }
}
\end{lstlisting}


\section{Conclusion}

ROBDD allows to efficiently manipulate functions appearing in various fields of computer science such as: Bounded Model Checking, Planning, Software Verification, Automatic Test Pattern Generation, Combinational Equivalence Checking or Combinatorial Interaction Testing.

However, ROBDD manipulation is memory intensive and various variants exist (such as "output inverter") in order to reduce the memory cost.

In this report, we introduce a new variant called "useless variable extraction" (a.k.a. "U-extract" for short).
This variant, by capturing useless variable, allows to reduce the number of nodes.


Using our implementation in OCaml against several benchmarks, we obtain an average reduction of 25\% when representing circuits, and 3\% when representing generated CNF formula.
Furthermore, we estimated the memory cost of this variant, in average, we observe a 30\% reduction when representing circuits and 3\% when representing CNF formula.


\newpage
\bibliography{biblio}{}
\bibliographystyle{plain}
\end{document}
